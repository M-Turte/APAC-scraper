# extraction.py

import time
import pandas as pd
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

TABLE_SELECTOR = "table.border"

def extract_all_pages(driver, timeout: int = 10) -> pd.DataFrame:
    """
    Extrai todas as p√°ginas de APACs: itera
    clicando em ‚Äúpr√≥xima p√°gina‚Äù at√© n√£o encontrar mais,
    acumulando somente as p√°ginas que contenham ‚ÄúNr. APAC‚Äù.
    Usa stale-element e compara√ß√£o de HTML para garantir
    que cada p√°gina seja nova.
    """
    dfs = []
    wait = WebDriverWait(driver, timeout)

    # garante que estamos no frame 'content'
    driver.switch_to.default_content()
    driver.switch_to.frame("content")

    page = 1
    while True:
        print(f"\n‚Äî P√°gina {page} ‚Äî")

        # aguarda e coleta todas as tables com class="border"
        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, TABLE_SELECTOR)))
        tables = driver.find_elements(By.CSS_SELECTOR, TABLE_SELECTOR)
        if not tables:
            print("‚ùå N√£o encontrei nenhuma tabela nesta p√°gina.")
        else:
            # escolhe tabela de resultados pela maior # de <tr>
            table = max(tables, key=lambda t: len(t.find_elements(By.TAG_NAME, "tr")))
            html_before = table.get_attribute("outerHTML")
            df_raw = pd.read_html(html_before, flavor="lxml", header=None)[0]
            print(f"  Linhas brutas: {df_raw.shape[0]}")

            # tenta localizar o cabe√ßalho "Nr. APAC"
            mask = df_raw.eq("Nr. APAC").any(axis=1)
            if mask.any():
                idx = mask.idxmax()
                header = df_raw.iloc[idx].tolist()
                df_page = df_raw.iloc[idx+1 :].copy()
                df_page.columns = header
                print(f"  Carregados {df_page.shape[0]} registros ap√≥s cabe√ßalho.")
                dfs.append(df_page)
            else:
                print("‚ö†Ô∏è  Cabe√ßalho 'Nr. APAC' n√£o encontrado; pulando p√°gina.")

        # tenta avan√ßar
        try:
            # tenta imagem ‚Äúon‚Äù primeiro, depois ‚Äúoff‚Äù
            try:
                img = driver.find_element(By.CSS_SELECTOR, "img[src*='bt_proximo1_on.gif']")
            except NoSuchElementException:
                img = driver.find_element(By.CSS_SELECTOR, "img[src*='bt_proximo1.gif']")
            link = img.find_element(By.XPATH, "./ancestor::a[1]")
            print("‚è≠Ô∏è Clicando em pr√≥xima p√°gina‚Ä¶")

            # robust wait: stale + HTML diferente
            link.click()
            wait.until(EC.staleness_of(table))
            wait.until(lambda d: d.find_element(By.CSS_SELECTOR, TABLE_SELECTOR)
                               .get_attribute("outerHTML") != html_before)
            time.sleep(0.5)  # opcional
            page += 1

        except (NoSuchElementException, TimeoutException):
            print("üîö Bot√£o de pr√≥xima p√°gina n√£o encontrado ou timeout. Finalizando.")
            break

    # concatena tudo
    if dfs:
        full = pd.concat(dfs, ignore_index=True)
        before = full.shape[0]
        full = full.dropna(how='all').reset_index(drop=True)
        removed = before - full.shape[0]
        if removed:
            print(f"üöÆ Removidas {removed} linhas vazias.")
        print(f"\n‚úÖ Total: {full.shape[0]} registros em {len(dfs)} p√°ginas v√°lidas.")
        return full
    else:
        print("‚ö†Ô∏è  Nenhum dado v√°lido coletado.")
        return pd.DataFrame()
